{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63485077-c0a0-4b39-9c2f-76f3a3d9fc31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/hpc127a02/.conda/envs/notebook/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import colorsys\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from functools import partial\n",
    "from multiprocessing import Pool\n",
    "import math\n",
    "from PIL import Image, ImageOps\n",
    "import dither\n",
    "import os\n",
    "import PIL\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from itertools import cycle\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b60e58a3-eb9a-4e90-9cde-2fb9362bc7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_waveform_rgb(\n",
    "    input_path,\n",
    "    output_path,\n",
    "    output_width=448,\n",
    "    output_height=448,\n",
    "    dither_input=False,\n",
    "    **kwargs\n",
    "):\n",
    "    # input_image = Image.fromarray(input_path)\n",
    "    input_image = Image.open(input_path)\n",
    "    image_to_process = ImageOps.contain(\n",
    "        input_image, (output_width, output_height)\n",
    "    )\n",
    "    input_image.close()\n",
    "    del input_image\n",
    "\n",
    "    # Determine offsets to center the resized image.\n",
    "    resized_width = image_to_process.width\n",
    "    resized_height = image_to_process.height\n",
    "    horizontal_offset = int((output_width - resized_width) / 2)\n",
    "    vertical_offset = int((output_height - resized_height) / 2)\n",
    "\n",
    "    rmat = np.zeros((448,448), dtype=np.uint8)\n",
    "    gmat = np.zeros((448,448), dtype=np.uint8)\n",
    "    bmat = np.zeros((448,448), dtype=np.uint8)\n",
    "    \n",
    "    for pixel_horizontal in range(resized_width):\n",
    "        # Creating a column list makes it easier to apply styles later on.\n",
    "        current_column = []\n",
    "\n",
    "        offset_horizontal_index = pixel_horizontal + horizontal_offset\n",
    "        for pixel_vertical in range(resized_height):\n",
    "            r, g, b = image_to_process.getpixel((pixel_horizontal, pixel_vertical))\n",
    "            # intensity = int(255.0 * (resized_height - pixel_vertical) / resized_height)\n",
    "            red = (r*(resized_height))//255\n",
    "            green = (g*(resized_height))//255\n",
    "            blue = (b*(resized_height))//255\n",
    "\n",
    "            current_column.append((red, green, blue))\n",
    "\n",
    "        for offset_vertical_index, color in enumerate(current_column, vertical_offset):\n",
    "            rmat[offset_horizontal_index,(color[0]-1)] = 255\n",
    "            gmat[offset_horizontal_index,(color[1]-1)] = 255\n",
    "            bmat[offset_horizontal_index,(color[2]-1)] = 255\n",
    "    \n",
    "    rmat = np.transpose(np.fliplr(rmat))\n",
    "    gmat = np.transpose(np.fliplr(gmat))\n",
    "    bmat = np.transpose(np.fliplr(bmat))\n",
    "    merged = np.stack((rmat,gmat,bmat), axis = -1)\n",
    "    output_image = Image.fromarray(merged,\"RGB\")\n",
    "    image_to_process.close()\n",
    "    del image_to_process\n",
    "\n",
    "    # Store the image in a lossless format.\n",
    "    # b = output_image # 내가 추가\n",
    "    output_image.save(os.path.splitext(output_path)[0] + \".png\", \"PNG\")\n",
    "    output_image.close()\n",
    "    del output_image\n",
    "    \n",
    "    return output_path\n",
    "def process_image(\n",
    "    image,\n",
    "    conversion_function,\n",
    "    input_folder,\n",
    "    output_folder,\n",
    "    output_width=1920,\n",
    "    output_height=1080,\n",
    "    replace_existing=False,\n",
    "    **kwargs,\n",
    "):\n",
    "    \"\"\"Process a single image with the given conversion_function.\n",
    "\n",
    "    Args:\n",
    "        image (str): Name of the image to process.\n",
    "        conversion_function (func): The function to use for the conversion.\n",
    "            Either \"image_to_waveform_rgb\" or \"image_to_vectorscope_hls\".\n",
    "        input_folder (str): Folder with images to process. Note: The script\n",
    "            will attempt to process ALL files inside this folder.\n",
    "        output_folder (str): Folder where the output images should be saved to.\n",
    "        output_width (int): Horizontal resolution of output image. This\n",
    "            determines how much \"storage\" you have to save the converted pixels.\n",
    "        output_height (int): Vertical resolution of output image. This\n",
    "            determines how much \"storage\" you have to save the converted pixels.\n",
    "        replace_existing (bool): Whether to overwrite existing files.\n",
    "        kwargs (dict): Keyword arguments to be passed on to the given\n",
    "            conversion_function.\n",
    "\n",
    "    Returns:\n",
    "        str: Path of the converted image.\n",
    "    \"\"\"\n",
    "    output_path = os.path.join(output_folder, image)\n",
    "    if os.path.isfile(output_path) and not replace_existing:\n",
    "        print(\"Skipping {}: Already exists.\".format(output_path))\n",
    "        return output_path\n",
    "\n",
    "    # print(\"Processing:\", image)\n",
    "    input_path = os.path.join(input_folder, image)\n",
    "    output_image = conversion_function(\n",
    "        input_path=input_path,\n",
    "        output_path=output_path,\n",
    "        output_width=output_width,\n",
    "        output_height=output_height,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "    return output_image\n",
    "\n",
    "\n",
    "def process_folder(\n",
    "    conversion_function,\n",
    "    input_folder,\n",
    "    output_folder,\n",
    "    output_width=1920,\n",
    "    output_height=1080,\n",
    "    replace_existing=False,\n",
    "    threads=8,\n",
    "    **kwargs,\n",
    "):\n",
    "    \"\"\"Process all images in a folder.\n",
    "\n",
    "    Args:\n",
    "        conversion_function (func): The function to use for the conversion.\n",
    "            Either \"image_to_waveform_rgb\" or \"image_to_vectorscope_hls\".\n",
    "        input_folder (str): Folder with images to process. Note: The script\n",
    "            will attempt to process ALL files inside this folder.\n",
    "        output_folder (str): Folder where the output images should be saved to.\n",
    "        output_width (int): Horizontal resolution of output image. This\n",
    "            determines how much \"storage\" you have to save the converted pixels.\n",
    "        output_height (int): Vertical resolution of output image. This\n",
    "            determines how much \"storage\" you have to save the converted pixels.\n",
    "        replace_existing (bool): Whether to overwrite existing files.\n",
    "        threads (int): How many threads should be used while processing.\n",
    "        kwargs (dict): Keyword arguments to be passed on to the given\n",
    "            conversion_function.\n",
    "\n",
    "    Examples:\n",
    "        ::\n",
    "\n",
    "            # Process an entire folder to Waveform\n",
    "            process_folder(\n",
    "                conversion_function=image_to_waveform_rgb,\n",
    "                input_folder=r\"some\\input\\folder\",\n",
    "                output_folder=r\"your\\output\\folder\",\n",
    "                threads=8,\n",
    "                replace_existing=False,\n",
    "                output_width=1920,\n",
    "                output_height=1080,\n",
    "                style=\"rgb_sorted\",\n",
    "                dither_input=True,\n",
    "                color_threshold=160,\n",
    "            )\n",
    "\n",
    "            # Process an entire folder to Vectorscope\n",
    "            process_folder(\n",
    "                conversion_function=image_to_vectorscope_hls,\n",
    "                input_folder=r\"some\\input\\folder\",\n",
    "                output_folder=r\"your\\output\\folder\",\n",
    "                threads=8,\n",
    "                replace_existing=False,\n",
    "                output_width=1920,\n",
    "                output_height=1080,\n",
    "                style=\"sorted\",\n",
    "                scale_to_fit=True,\n",
    "                output_resolution=512,\n",
    "                shades=8,\n",
    "                outline_with_remaining_pixels=True,\n",
    "                maintain_chunk_positions=True,\n",
    "                chunk_fill_color=None,\n",
    "            )\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    pathlib.Path(output_folder).mkdir(parents=True, exist_ok=True)\n",
    "    _, _, filenames = list(os.walk(input_folder))[0]\n",
    "\n",
    "    with Pool(threads) as pool:\n",
    "        pool.map(\n",
    "            partial(\n",
    "                process_image,\n",
    "                conversion_function=conversion_function,\n",
    "                input_folder=input_folder,\n",
    "                output_folder=output_folder,\n",
    "                output_width=output_width,\n",
    "                output_height=output_height,\n",
    "                replace_existing=replace_existing,\n",
    "                **kwargs,\n",
    "            ),\n",
    "            filenames,\n",
    "        )\n",
    "\n",
    "    message = \"Took: {} seconds to process {} images with {} threads.\"\n",
    "    print(message.format(time.time() - start_time, len(filenames), threads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6a41c0d-3166-4704-b4c4-bdf8266ef547",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneHotImageFolder(torchvision.datasets.ImageFolder):\n",
    "    def __init__(self, root, transform=None, target_transform=None):\n",
    "        super(OneHotImageFolder, self).__init__(root, transform, target_transform)\n",
    "        self.num_classes = len(self.classes)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # Get the original image and label\n",
    "        img, label = super(OneHotImageFolder, self).__getitem__(index)\n",
    "        \n",
    "        # One-hot encode the label\n",
    "        one_hot_label = F.one_hot(torch.tensor(label), num_classes=self.num_classes).float()\n",
    "        \n",
    "        return img, one_hot_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6cf1cc7-b606-48d3-9fc0-0b2a489231ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196\n",
      "193\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "fake_names = glob('./Celeb_df_2/Facecrop_dataset/Test/Fake/*')\n",
    "true_names = glob('./Celeb_df_2/Facecrop_dataset/Test/Real/*')\n",
    "print(len(fake_names))\n",
    "print(len(true_names))\n",
    "fake_names = sorted(fake_names)\n",
    "true_names = sorted(true_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b04eb469-fc7e-4e6d-ba3b-19751200e9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 39.618252754211426 seconds to process 196 images with 16 threads.\n"
     ]
    }
   ],
   "source": [
    "in_path = './Celeb_df_2/Facecrop_dataset/Test/Fake'\n",
    "out_path = './Celeb_df_2/Realwave_dataset/Test/Fake'\n",
    "\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "process_folder(\n",
    "    conversion_function=image_to_waveform_rgb,\n",
    "    input_folder=in_path,\n",
    "    output_folder=out_path,\n",
    "    threads=16,\n",
    "    replace_existing=False,\n",
    "    output_width=448,\n",
    "    output_height=448,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7abb4e81-3aa4-4247-bfce-029c3cf9e06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 40.09684610366821 seconds to process 193 images with 16 threads.\n"
     ]
    }
   ],
   "source": [
    "in_path = './Celeb_df_2/Facecrop_dataset/Test/Real'\n",
    "out_path = './Celeb_df_2/Realwave_dataset/Test/Real'\n",
    "\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "process_folder(\n",
    "    conversion_function=image_to_waveform_rgb,\n",
    "    input_folder=in_path,\n",
    "    output_folder=out_path,\n",
    "    threads=16,\n",
    "    replace_existing=False,\n",
    "    output_width=448,\n",
    "    output_height=448,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a8d9afa-83d0-478b-be04-cf4d39367c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 353.0947775840759 seconds to process 1778 images with 16 threads.\n"
     ]
    }
   ],
   "source": [
    "in_path = './Celeb_df_2/Facecrop_dataset/Train/Fake'\n",
    "out_path = './Celeb_df_2/Realwave_dataset/Train/Fake'\n",
    "\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "process_folder(\n",
    "    conversion_function=image_to_waveform_rgb,\n",
    "    input_folder=in_path,\n",
    "    output_folder=out_path,\n",
    "    threads=16,\n",
    "    replace_existing=False,\n",
    "    output_width=448,\n",
    "    output_height=448,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1fc2a9f4-9dda-469d-8926-40ee89ca9851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 351.4315650463104 seconds to process 1766 images with 16 threads.\n"
     ]
    }
   ],
   "source": [
    "in_path = './Celeb_df_2/Facecrop_dataset/Train/Real'\n",
    "out_path = './Celeb_df_2/Realwave_dataset/Train/Real'\n",
    "\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "process_folder(\n",
    "    conversion_function=image_to_waveform_rgb,\n",
    "    input_folder=in_path,\n",
    "    output_folder=out_path,\n",
    "    threads=16,\n",
    "    replace_existing=False,\n",
    "    output_width=448,\n",
    "    output_height=448,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73dfd841-03f2-4af5-80e7-fd169876bc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1766 1778\n"
     ]
    }
   ],
   "source": [
    "aa = glob('./Celeb_df_2/Realwave_dataset/Train/Real/*')\n",
    "bb = glob('./Celeb_df_2/Realwave_dataset/Train/Fake/*')\n",
    "print(len(aa), len(bb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a80444-7f2c-48fb-a1c9-dc0e3385442f",
   "metadata": {},
   "source": [
    "### 학습시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbb2ced0-dc2b-4cec-b39b-9771023022de",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = './Celeb_df_2/Realwave_dataset/Train'\n",
    "valid_dir = './Celeb_df_2/Realwave_dataset/Test'\n",
    "\n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()\n",
    "                                           ])\n",
    "\n",
    "train_dataset = OneHotImageFolder(root=train_dir,transform=transform)\n",
    "valid_dataset = OneHotImageFolder(root=valid_dir,transform=transform)\n",
    "\n",
    "\n",
    "batchsize = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c10f0570-6435-45e5-acd7-9ec907699343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Fake': 0, 'Real': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = os.listdir(train_dir)\n",
    "labeled_classes = {i:index for index, i in enumerate(classes)}\n",
    "labeled_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40eee4c6-3360-416b-92da-d49f54d02fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size= batchsize, shuffle = True)\n",
    "valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=batchsize, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32a15027-bf23-42c0-9c1a-ff3ce2699e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b734860e-9c54-4ab2-a9af-faaedb903726",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_planes, planes, stride):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.actfunc = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.stride = stride\n",
    "\n",
    "        if stride == 2:\n",
    "            self.shortcut = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            self.padzeros = in_planes\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.actfunc(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        if self.stride == 2:\n",
    "            shortcut = self.shortcut(x)\n",
    "            batch_size, _, height, width = shortcut.size()\n",
    "            zeros = torch.zeros(batch_size, self.padzeros, height, width).to(x.device)\n",
    "            shortcut = torch.cat((shortcut, zeros), dim=1)\n",
    "            out += shortcut\n",
    "        else:\n",
    "            out += x\n",
    "        \n",
    "        return out\n",
    "    \n",
    "class Slimres(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_blocks, num_classes=2):\n",
    "        super(Slimres, self).__init__()\n",
    "        self.layer1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.layer2 = nn.BatchNorm2d(32)\n",
    "        self.layer3 = nn.ReLU()\n",
    "        self.layer4 = self._make_layer(ConvBlock, 32, 32, num_blocks[0], 1)\n",
    "        self.layer5 = self._make_layer(ConvBlock, 32, 64, 1, 2)\n",
    "        self.layer6 = self._make_layer(ConvBlock, 64, 64, num_blocks[1], 1)\n",
    "        self.layer7 = self._make_layer(ConvBlock, 64, 128, 1, 2)\n",
    "        self.layer8 = self._make_layer(ConvBlock, 128, 128, num_blocks[2], 1)\n",
    "        self.layer9 = nn.AvgPool2d((28,28))\n",
    "        self.linear = nn.Linear(128*16,2)\n",
    "\n",
    "    def _make_layer(self, block, inplanes, planes, num_blocks, stride):\n",
    "        layers = []\n",
    "        for i in range(num_blocks):\n",
    "            layers.append(block(inplanes, planes, stride))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        # print(out.shape)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        # print(out.shape)\n",
    "        out = self.layer6(out)\n",
    "        out = self.layer7(out)\n",
    "        # print(out.shape)\n",
    "        out = self.layer8(out)\n",
    "        out = self.layer9(out)\n",
    "        # print(out.size())\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b099a7c8-7e9f-47d9-bd63-7b1f22375f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): Slimres(\n",
       "    (layer1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (layer2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (layer3): ReLU()\n",
       "    (layer4): Sequential(\n",
       "      (0): ConvBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (actfunc): ReLU()\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): ConvBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (actfunc): ReLU()\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): ConvBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (actfunc): ReLU()\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer5): Sequential(\n",
       "      (0): ConvBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (actfunc): ReLU()\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (layer6): Sequential(\n",
       "      (0): ConvBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (actfunc): ReLU()\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): ConvBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (actfunc): ReLU()\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer7): Sequential(\n",
       "      (0): ConvBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (actfunc): ReLU()\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (layer8): Sequential(\n",
       "      (0): ConvBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (actfunc): ReLU()\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): ConvBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (actfunc): ReLU()\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer9): AvgPool2d(kernel_size=(28, 28), stride=(28, 28), padding=0)\n",
       "    (linear): Linear(in_features=2048, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model = Slimres([3,2,2])\n",
    "cnn_model = nn.DataParallel(cnn_model)\n",
    "cnn_model = cnn_model.to(device)\n",
    "loss_function = nn.CrossEntropyLoss().to(device)\n",
    "cnn_optimizer = torch.optim.Adam(cnn_model.parameters(), lr=1e-3)\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.kaiming_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_uniform_(m.weight)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "cnn_model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c4550f-65cd-4595-9970-c7157eaa4188",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200 [Train]: 100%|██████████| 222/222 [02:31<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.5018 || Training Acc: 0.5367\n",
      "Validation Loss: 1.0004 || Validation Acc: 0.5024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.0860 || Training Acc: 0.5183\n",
      "Validation Loss: 2.9638 || Validation Acc: 0.5024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.7293 || Training Acc: 0.5409\n",
      "Validation Loss: 5.5057 || Validation Acc: 0.5024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.6291 || Training Acc: 0.5274\n",
      "Validation Loss: 9.9436 || Validation Acc: 0.5024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.8565 || Training Acc: 0.5440\n",
      "Validation Loss: 10.2639 || Validation Acc: 0.5024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.7881 || Training Acc: 0.5324\n",
      "Validation Loss: 4.1987 || Validation Acc: 0.5024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.6185 || Training Acc: 0.5547\n",
      "Validation Loss: 4.8509 || Validation Acc: 0.5024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.9503 || Training Acc: 0.5576\n",
      "Validation Loss: 1.0238 || Validation Acc: 0.5024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.8849 || Training Acc: 0.5700\n",
      "Validation Loss: 8.4139 || Validation Acc: 0.5024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.9692 || Training Acc: 0.5815\n",
      "Validation Loss: 2.9326 || Validation Acc: 0.5024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.7899 || Training Acc: 0.5714\n",
      "Validation Loss: 0.9320 || Validation Acc: 0.5024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.7597 || Training Acc: 0.5739\n",
      "Validation Loss: 2.8548 || Validation Acc: 0.5024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.8811 || Training Acc: 0.6041\n",
      "Validation Loss: 1.9225 || Validation Acc: 0.5118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.7415 || Training Acc: 0.6095\n",
      "Validation Loss: 1.4907 || Validation Acc: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.6260 || Training Acc: 0.6264\n",
      "Validation Loss: 0.2497 || Validation Acc: 0.5545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.7221 || Training Acc: 0.6490\n",
      "Validation Loss: 0.6179 || Validation Acc: 0.5047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.5012 || Training Acc: 0.6589\n",
      "Validation Loss: 1.5870 || Validation Acc: 0.6019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.6938 || Training Acc: 0.6600\n",
      "Validation Loss: 1.6462 || Validation Acc: 0.5047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4960 || Training Acc: 0.6594\n",
      "Validation Loss: 0.8751 || Validation Acc: 0.6374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.7110 || Training Acc: 0.6713\n",
      "Validation Loss: 0.2846 || Validation Acc: 0.6303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4675 || Training Acc: 0.6843\n",
      "Validation Loss: 0.4763 || Validation Acc: 0.5664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4300 || Training Acc: 0.6840\n",
      "Validation Loss: 1.0150 || Validation Acc: 0.6374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.7467 || Training Acc: 0.6874\n",
      "Validation Loss: 1.7249 || Validation Acc: 0.5403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.3862 || Training Acc: 0.7012\n",
      "Validation Loss: 1.2201 || Validation Acc: 0.5427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.6430 || Training Acc: 0.6984\n",
      "Validation Loss: 1.2810 || Validation Acc: 0.5237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4926 || Training Acc: 0.7119\n",
      "Validation Loss: 1.0393 || Validation Acc: 0.5829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4121 || Training Acc: 0.7144\n",
      "Validation Loss: 1.1742 || Validation Acc: 0.6232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.0681 || Training Acc: 0.7136\n",
      "Validation Loss: 1.2199 || Validation Acc: 0.5498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.7431 || Training Acc: 0.7226\n",
      "Validation Loss: 0.8945 || Validation Acc: 0.6114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.8265 || Training Acc: 0.7240\n",
      "Validation Loss: 0.8003 || Validation Acc: 0.5995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.9302 || Training Acc: 0.7398\n",
      "Validation Loss: 1.3004 || Validation Acc: 0.5213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.5680 || Training Acc: 0.7396\n",
      "Validation Loss: 1.0262 || Validation Acc: 0.5782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.3386 || Training Acc: 0.7427\n",
      "Validation Loss: 0.2565 || Validation Acc: 0.6445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.3595 || Training Acc: 0.7472\n",
      "Validation Loss: 0.4092 || Validation Acc: 0.5877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.3919 || Training Acc: 0.7466\n",
      "Validation Loss: 1.3139 || Validation Acc: 0.5900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4521 || Training Acc: 0.7531\n",
      "Validation Loss: 0.5610 || Validation Acc: 0.5332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.3609 || Training Acc: 0.7683\n",
      "Validation Loss: 0.3016 || Validation Acc: 0.6090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4801 || Training Acc: 0.7706\n",
      "Validation Loss: 0.8400 || Validation Acc: 0.6209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.5187 || Training Acc: 0.7695\n",
      "Validation Loss: 2.5383 || Validation Acc: 0.5403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.6573 || Training Acc: 0.7850\n",
      "Validation Loss: 2.8382 || Validation Acc: 0.5355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.3407 || Training Acc: 0.7850\n",
      "Validation Loss: 0.3599 || Validation Acc: 0.6019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.3376 || Training Acc: 0.7971\n",
      "Validation Loss: 1.0006 || Validation Acc: 0.5972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.5915 || Training Acc: 0.8076\n",
      "Validation Loss: 0.9149 || Validation Acc: 0.6185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.3431 || Training Acc: 0.8124\n",
      "Validation Loss: 1.5069 || Validation Acc: 0.5806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4983 || Training Acc: 0.8160\n",
      "Validation Loss: 0.4440 || Validation Acc: 0.5877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.5311 || Training Acc: 0.8284\n",
      "Validation Loss: 1.1503 || Validation Acc: 0.5735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.5748 || Training Acc: 0.8341\n",
      "Validation Loss: 0.4415 || Validation Acc: 0.5687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0960 || Training Acc: 0.8355\n",
      "Validation Loss: 1.4075 || Validation Acc: 0.5829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.3799 || Training Acc: 0.8451\n",
      "Validation Loss: 0.3587 || Validation Acc: 0.6066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.3426 || Training Acc: 0.8448\n",
      "Validation Loss: 1.4982 || Validation Acc: 0.5664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1357 || Training Acc: 0.8657\n",
      "Validation Loss: 0.6397 || Validation Acc: 0.6043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/200 [Train]: 100%|██████████| 222/222 [01:12<00:00,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.5902 || Training Acc: 0.8629\n",
      "Validation Loss: 0.5835 || Validation Acc: 0.5569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/200 [Train]: 100%|██████████| 222/222 [01:11<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.2797 || Training Acc: 0.8725\n",
      "Validation Loss: 1.3914 || Validation Acc: 0.5877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/200 [Train]: 100%|██████████| 222/222 [01:09<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.6168 || Training Acc: 0.8742\n",
      "Validation Loss: 1.0646 || Validation Acc: 0.5806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0986 || Training Acc: 0.8804\n",
      "Validation Loss: 0.5889 || Validation Acc: 0.5877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.6468 || Training Acc: 0.8840\n",
      "Validation Loss: 0.7688 || Validation Acc: 0.5687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1608 || Training Acc: 0.8874\n",
      "Validation Loss: 0.6699 || Validation Acc: 0.5995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1209 || Training Acc: 0.8987\n",
      "Validation Loss: 1.0990 || Validation Acc: 0.5877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0958 || Training Acc: 0.9086\n",
      "Validation Loss: 1.0326 || Validation Acc: 0.5806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.2573 || Training Acc: 0.9058\n",
      "Validation Loss: 1.1774 || Validation Acc: 0.5972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0426 || Training Acc: 0.9010\n",
      "Validation Loss: 1.7225 || Validation Acc: 0.5900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1436 || Training Acc: 0.9162\n",
      "Validation Loss: 2.1356 || Validation Acc: 0.5237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.2672 || Training Acc: 0.9179\n",
      "Validation Loss: 0.8314 || Validation Acc: 0.5664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1092 || Training Acc: 0.9210\n",
      "Validation Loss: 1.9893 || Validation Acc: 0.5877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.2006 || Training Acc: 0.9216\n",
      "Validation Loss: 0.5348 || Validation Acc: 0.6161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.2794 || Training Acc: 0.9300\n",
      "Validation Loss: 0.8073 || Validation Acc: 0.5972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1090 || Training Acc: 0.9266\n",
      "Validation Loss: 1.7193 || Validation Acc: 0.5853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0955 || Training Acc: 0.9309\n",
      "Validation Loss: 1.6778 || Validation Acc: 0.5972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0167 || Training Acc: 0.9328\n",
      "Validation Loss: 1.1247 || Validation Acc: 0.6137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.3241 || Training Acc: 0.9376\n",
      "Validation Loss: 2.0118 || Validation Acc: 0.5782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1902 || Training Acc: 0.9461\n",
      "Validation Loss: 1.1256 || Validation Acc: 0.6090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1899 || Training Acc: 0.9337\n",
      "Validation Loss: 1.4083 || Validation Acc: 0.6137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.2143 || Training Acc: 0.9419\n",
      "Validation Loss: 2.2322 || Validation Acc: 0.5900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0057 || Training Acc: 0.9430\n",
      "Validation Loss: 2.4279 || Validation Acc: 0.6019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.7824 || Training Acc: 0.9495\n",
      "Validation Loss: 0.3582 || Validation Acc: 0.5687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1109 || Training Acc: 0.9441\n",
      "Validation Loss: 0.0540 || Validation Acc: 0.5735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0327 || Training Acc: 0.9481\n",
      "Validation Loss: 4.4939 || Validation Acc: 0.5972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0023 || Training Acc: 0.9486\n",
      "Validation Loss: 2.3208 || Validation Acc: 0.6043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.2609 || Training Acc: 0.9455\n",
      "Validation Loss: 0.5811 || Validation Acc: 0.6161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.2515 || Training Acc: 0.9549\n",
      "Validation Loss: 0.5080 || Validation Acc: 0.5853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0610 || Training Acc: 0.9551\n",
      "Validation Loss: 0.3724 || Validation Acc: 0.5900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0115 || Training Acc: 0.9608\n",
      "Validation Loss: 2.4032 || Validation Acc: 0.5782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.2272 || Training Acc: 0.9560\n",
      "Validation Loss: 1.9697 || Validation Acc: 0.6090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0273 || Training Acc: 0.9602\n",
      "Validation Loss: 1.6324 || Validation Acc: 0.6114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1942 || Training Acc: 0.9582\n",
      "Validation Loss: 4.1823 || Validation Acc: 0.6043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0682 || Training Acc: 0.9650\n",
      "Validation Loss: 2.9306 || Validation Acc: 0.5521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1526 || Training Acc: 0.9622\n",
      "Validation Loss: 1.7401 || Validation Acc: 0.5948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0067 || Training Acc: 0.9650\n",
      "Validation Loss: 1.3665 || Validation Acc: 0.6137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0164 || Training Acc: 0.9687\n",
      "Validation Loss: 3.1192 || Validation Acc: 0.6256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0045 || Training Acc: 0.9647\n",
      "Validation Loss: 2.0845 || Validation Acc: 0.6161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0299 || Training Acc: 0.9613\n",
      "Validation Loss: 3.3157 || Validation Acc: 0.6114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0351 || Training Acc: 0.9630\n",
      "Validation Loss: 1.8706 || Validation Acc: 0.6066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 93/200 [Train]: 100%|██████████| 222/222 [01:09<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0446 || Training Acc: 0.9726\n",
      "Validation Loss: 2.1893 || Validation Acc: 0.5877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0195 || Training Acc: 0.9701\n",
      "Validation Loss: 2.1275 || Validation Acc: 0.5664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 95/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0238 || Training Acc: 0.9661\n",
      "Validation Loss: 2.0844 || Validation Acc: 0.5829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 96/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0026 || Training Acc: 0.9625\n",
      "Validation Loss: 3.8762 || Validation Acc: 0.5995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97/200 [Train]: 100%|██████████| 222/222 [01:08<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0241 || Training Acc: 0.9664\n",
      "Validation Loss: 1.5352 || Validation Acc: 0.5735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 98/200 [Train]:  51%|█████▏    | 114/222 [00:35<00:32,  3.29it/s]"
     ]
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "train_loss =[]\n",
    "val_loss=[]\n",
    "train_acc=[]\n",
    "val_acc=[]\n",
    "acc_max =0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    cnn_model.train()\n",
    "    # Initialize the progress bar\n",
    "    train_loop = tqdm(train_dataloader, desc=f'Epoch {epoch+1}/{num_epochs} [Train]')\n",
    "    train_true = []\n",
    "    train_pred = []\n",
    "    \n",
    "    for images, labels in train_loop:  # Make sure to iterate over train_loop here\n",
    "        \n",
    "        # labels = labels.type(torch.LongTensor)\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = cnn_model(images)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        cnn_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        cnn_optimizer.step()\n",
    "        \n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        # print(torch.max(outputs.data,1))\n",
    "        # print(labels.data)\n",
    "        __, true = torch.max(labels.data,1)\n",
    "        \n",
    "        train_true.extend(true.view(-1).cpu().numpy())\n",
    "        train_pred.extend(preds.view(-1).cpu().numpy())\n",
    "        \n",
    "\n",
    "    cnn_model.eval()\n",
    "    val_true = []\n",
    "    val_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in valid_dataloader:\n",
    "            # labels = labels.type(torch.LongTensor)\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = cnn_model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            __, trueval = torch.max(labels.data, 1)\n",
    "            val_pred.extend(predicted.view(-1).cpu().numpy())\n",
    "            val_true.extend(trueval.view(-1).cpu().numpy())\n",
    "\n",
    "            validation_loss = loss_function(outputs, labels)\n",
    "\n",
    "\n",
    "    train_acc.append(accuracy_score(train_true,train_pred))\n",
    "    val_acc.append(accuracy_score(val_true,val_pred))\n",
    "    train_loss.append(loss.item())\n",
    "    val_loss.append(validation_loss.item())\n",
    "    print(f'Training Loss: {loss.item():.4f} || Training Acc: {train_acc[-1]:.4f}')\n",
    "    print(f'Validation Loss: {validation_loss.item():.4f} || Validation Acc: {val_acc[-1]:.4f}')\n",
    "    \n",
    "    if (val_acc[-1]) > acc_max:\n",
    "        torch.save(cnn_model, f'./Test_results/test6_result/model_checkpoint_{epoch+1}_{val_acc[-1]:.4f}.pt')\n",
    "        acc_max = (val_acc[-1])\n",
    "    # if epoch % 30 == 0:\n",
    "    #     torch.save(model, f'./resnet50/model_checkpoint_{epoch}_{val_loss[-1]:.4f}.pt')\n",
    "history = {'train_loss': train_loss, 'val_loss':val_loss, 'train_acc':train_acc, 'val_acc':val_acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf27b41-374a-4dfd-b122-ffd27b9fe011",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,4))\n",
    "plt.plot(history['train_acc'],mark./Celeb_df_2/Realwave_dataset/2, label = \"Train accuracy\")\n",
    "plt.plot(history['val_acc'],marker = 'o', ms = 2, label = \"Valid accuracy\")\n",
    "plt.title(f'Accuracy')\n",
    "plt.ylabel('Acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(), plt.grid()\n",
    "\n",
    "plt.figure(figsize = (8,4))\n",
    "plt.plot(history['train_loss'],marker = 'o', ms = 2, label = \"Train loss\")\n",
    "plt.plot(history['val_loss'],marker = 'o', ms = 2, label = \"Valid loss\")\n",
    "plt.title(f'Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(), plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6c24ba-cfc3-463a-8450-55b9bf90562a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook",
   "language": "python",
   "name": "notebook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
